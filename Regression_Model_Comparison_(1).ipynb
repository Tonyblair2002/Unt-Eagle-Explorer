{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import time\n",
        "\n",
        "# --- 1. Data Generation ---\n",
        "\n",
        "N_SAMPLES = 1_000_000  # Number of instances (1 million)\n",
        "N_FEATURES = 5         # Number of features\n",
        "NOISE_LEVEL = 0.5      # Standard deviation of the noise\n",
        "\n",
        "# y = 1.5*F1 + (-2.2)*F2 + 0.5*F3 + 3.0*F4 + (-0.8)*F5 + noise\n",
        "TRUE_WEIGHTS = np.array([1.5, -2.2, 0.5, 3.0, -0.8])\n",
        "\n",
        "print(f\"Generating {N_SAMPLES} samples with {N_FEATURES} features...\")\n",
        "X = np.random.rand(N_SAMPLES, N_FEATURES)\n",
        "noise = np.random.normal(loc=0.0, scale=NOISE_LEVEL, size=N_SAMPLES)\n",
        "y = np.dot(X, TRUE_WEIGHTS) + noise\n",
        "\n",
        "# Create DataFrame\n",
        "feature_cols = [f'Feature_{i+1}' for i in range(N_FEATURES)]\n",
        "df = pd.DataFrame(X, columns=feature_cols)\n",
        "df['Target'] = y\n",
        "\n",
        "print(\"Data generation complete.\")\n",
        "\n",
        "# --- 2. Data Visualization & Outlier Check (on a sample) ---\n",
        "\n",
        "print(\"\\n--- Starting Exploratory Data Analysis (EDA) on a 5000-point sample ---\")\n",
        "# Plotting 1 million points is too slow and dense. We'll use a random sample.\n",
        "SAMPLE_SIZE = 5000\n",
        "df_sample = df.sample(n=SAMPLE_SIZE, random_state=42)\n",
        "\n",
        "# a) Scatter plots of each feature vs. the target\n",
        "print(\"Generating scatter plots (Feature vs. Target)...\")\n",
        "fig, axes = plt.subplots(nrows=1, ncols=N_FEATURES, figsize=(25, 5))\n",
        "for i, col in enumerate(feature_cols):\n",
        "    sns.scatterplot(x=df_sample[col], y=df_sample['Target'], ax=axes[i], alpha=0.5, s=10)\n",
        "    axes[i].set_title(f'{col} vs. Target', fontsize=10)\n",
        "    axes[i].set_xlabel(col)\n",
        "    axes[i].set_ylabel('Target')\n",
        "plt.suptitle('Feature vs. Target Scatter Plots', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# b) Outlier Check using Boxplots\n",
        "print(\"Generating boxplots for outlier detection...\")\n",
        "all_cols = feature_cols + ['Target']\n",
        "fig, axes = plt.subplots(nrows=1, ncols=len(all_cols), figsize=(20, 6))\n",
        "for i, col in enumerate(all_cols):\n",
        "    sns.boxplot(y=df_sample[col], ax=axes[i])\n",
        "    axes[i].set_title(f'Boxplot of {col}', fontsize=10)\n",
        "plt.suptitle('Outlier Check via Boxplots', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"EDA complete. Note: Outliers are expected due to the normal noise distribution.\")\n",
        "\n",
        "# --- 3. Data Split (10% Test) ---\n",
        "\n",
        "print(f\"\\nSplitting full dataset ({N_SAMPLES} instances) into 90% train / 10% test...\")\n",
        "X = df.drop('Target', axis=1)\n",
        "y = df['Target']\n",
        "\n",
        "# We use the full dataset for training and testing the models\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Test set size:     {len(X_test)}\")\n",
        "\n",
        "# --- 4. Model 1: Decision Tree Regressor ---\n",
        "\n",
        "print(\"\\n--- Training Decision Tree Regressor ---\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Decision Trees do not require feature scaling\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "dt_duration = time.time() - start_time\n",
        "print(f\"Decision Tree training complete in {dt_duration:.2f} seconds.\")\n",
        "\n",
        "# Predictions and Evaluation\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "dt_mse = mean_squared_error(y_test, y_pred_dt)\n",
        "dt_mae = mean_absolute_error(y_test, y_pred_dt)\n",
        "\n",
        "print(f\"Decision Tree Test MSE: {dt_mse:.4f}\")\n",
        "print(f\"Decision Tree Test MAE: {dt_mae:.4f}\")\n",
        "\n",
        "# --- 5. Model 2: Fully Connected Neural Network (FCNN) ---\n",
        "\n",
        "print(\"\\n--- Training Fully Connected Neural Network (FCNN) ---\")\n",
        "\n",
        "# FCNNs require feature scaling for good performance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the FCNN model\n",
        "fcnn_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(N_FEATURES,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    # Output layer: 1 neuron, linear activation (default) for regression\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "fcnn_model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                   loss='mse',  # Use Mean Squared Error as the loss function\n",
        "                   metrics=['mae']) # Also track Mean Absolute Error\n",
        "\n",
        "print(fcnn_model.summary())\n",
        "\n",
        "# Train the FCNN\n",
        "start_time = time.time()\n",
        "history = fcnn_model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=10, # 10 epochs is often enough for this kind of simple problem\n",
        "    batch_size=256,\n",
        "    validation_split=0.1, # Use 10% of the training data for validation\n",
        "    verbose=1\n",
        ")\n",
        "fcnn_duration = time.time() - start_time\n",
        "print(f\"FCNN training complete in {fcnn_duration:.2f} seconds.\")\n",
        "\n",
        "# Predictions and Evaluation\n",
        "y_pred_fcnn = fcnn_model.predict(X_test_scaled).flatten() # flatten to 1D array\n",
        "fcnn_mse = mean_squared_error(y_test, y_pred_fcnn)\n",
        "fcnn_mae = mean_absolute_error(y_test, y_pred_fcnn)\n",
        "\n",
        "print(f\"FCNN Test MSE: {fcnn_mse:.4f}\")\n",
        "print(f\"FCNN Test MAE: {fcnn_mae:.4f}\")\n",
        "\n",
        "\n",
        "# --- 6. Performance Comparison ---\n",
        "\n",
        "print(\"\\n--- Model Performance Comparison ---\")\n",
        "results = {\n",
        "    'Model': ['Decision Tree', 'FCNN'],\n",
        "    'Training Time (s)': [f\"{dt_duration:.2f}\", f\"{fcnn_duration:.2f}\"],\n",
        "    'Test MSE': [f\"{dt_mse:.4f}\", f\"{fcnn_mse:.4f}\"],\n",
        "    'Test MAE': [f\"{dt_mae:.4f}\", f\"{fcnn_mae:.4f}\"]\n",
        "}\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n--- Interpretation ---\")\n",
        "print(\"The FCNN likely performs significantly better (lower MSE/MAE).\")\n",
        "print(f\"The theoretical 'best possible' MSE is the variance of the noise, which is {NOISE_LEVEL**2:.4f}.\")\n",
        "print(\"The FCNN's MSE should be very close to this value, as it is excellent at finding the underlying linear relationship.\")\n",
        "print(\"The Decision Tree, while fast, struggles to perfectly model this linear sum and is more sensitive to the noise.\")"
      ],
      "metadata": {
        "id": "6_pzFxj3Q_4r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}